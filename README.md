<div align="center">

<!-- Header Banner -->
<img src="https://capsule-render.vercel.app/api?type=waving&color=gradient&customColorList=6,11,20&height=180&section=header&text=Sumanth%20Malipeddi&fontSize=42&fontColor=fff&animation=twinkling&fontAlignY=32&desc=Data%20Engineer%20|%20Building%20Production%20Pipelines%20That%20Power%20AI&descSize=16&descAlignY=51" width="100%"/>

<!-- Animated Typing -->
<a href="https://git.io/typing-svg"><img src="https://readme-typing-svg.herokuapp.com?font=Fira+Code&weight=600&size=28&duration=3000&pause=1000&color=3B9CFF&center=true&vCenter=true&multiline=true&repeat=true&width=800&height=100&lines=Associate+Data+Science+Engineer+%40+GetMySaas;Apache+Airflow+â€¢+Kafka+â€¢+dbt+â€¢+Iceberg+â€¢+pgvector;MS+Data+Science+%40+IISER+Tirupati+(9.5+CGPA)" alt="Typing SVG" /></a>

<!-- Social Badges -->
<p align="center">
  <a href="https://linkedin.com/in/sumanth-malipeddi">
    <img src="https://img.shields.io/badge/LinkedIn-0077B5?style=for-the-badge&logo=linkedin&logoColor=white" alt="LinkedIn"/>
  </a>
  <a href="mailto:sumanth.9666@gmail.com">
    <img src="https://img.shields.io/badge/Email-D14836?style=for-the-badge&logo=gmail&logoColor=white" alt="Email"/>
  </a>
  <a href="https://x.com/Sumanth9666">
    <img src="https://img.shields.io/badge/Twitter-1DA1F2?style=for-the-badge&logo=x&logoColor=white" alt="Twitter"/>
  </a>
  <a href="https://github.com/sumanthmalipeddi">
    <img src="https://img.shields.io/badge/GitHub-100000?style=for-the-badge&logo=github&logoColor=white" alt="GitHub"/>
  </a>
</p>

<!-- Profile Stats -->
<p align="center">
  <img src="https://komarev.com/ghpvc/?username=sumanthmalipeddi&label=Profile%20Views&color=0e75b6&style=for-the-badge" alt="Profile views" />
  <img src="https://img.shields.io/github/followers/sumanthmalipeddi?label=Followers&style=for-the-badge&color=blue" alt="followers"/>
  <img src="https://img.shields.io/github/stars/sumanthmalipeddi?label=Stars&style=for-the-badge&color=yellow" alt="stars"/>
</p>

</div>

---

## ğŸ“‘ Table of Contents

- [ğŸ‘¨â€ğŸ’» About Me](#-about-me)
- [ğŸ’¼ Professional Experience](#-professional-experience)
- [ğŸ› ï¸ Tech Stack](#ï¸-tech-stack)
- [ğŸš€ Featured Projects](#-featured-projects)
- [ğŸ“Š GitHub Analytics](#-github-analytics)
- [ğŸ† Achievements & Certifications](#-achievements--certifications)
- [ğŸ“š Learning Journey](#-learning-journey)
- [ğŸ“ Education](#-education)
- [ğŸ“« Let's Connect](#-lets-connect)

---

## ğŸ‘¨â€ğŸ’» About Me

<img align="right" alt="Coding" width="400" src="https://raw.githubusercontent.com/abhisheknaiidu/abhisheknaiidu/master/code.gif">

```yaml
name: Sumanth Malipeddi
role: Associate Data Science Engineer
company: GetMySaas
location: ğŸ“ Tirupati, Andhra Pradesh, India
education: ğŸ“ MS Data Science & AI | IISER Tirupati
gpa: 9.50/10
experience: 4+ years in data analytics & engineering

specialization:
  - Production Data Pipelines
  - Real-time Streaming Architecture
  - Lakehouse Design (Iceberg, dbt, Trino)
  - RAG Systems & Semantic Search
  - MLOps & Model Deployment

currently_building:
  - 15+ Airflow DAGs for data ingestion
  - Kafka streaming pipelines
  - pgvector + OpenSearch hybrid search
  - Document intelligence workflows

daily_stack:
  orchestration: [Apache Airflow, Dagster]
  streaming: [Apache Kafka, Redis]
  transformation: [dbt, Pandas, PySpark]
  storage: [Apache Iceberg, PostgreSQL, S3]
  ai_tools: [Claude, GPT-5, Perplexity]

learning_streak: 120+ days DSA consistency ğŸ”¥

philosophy: |
  "Production pipelines live in edge cases, not happy paths.
   Real learning happens when things break."
```

<div align="left">

### ğŸ¯ What I Do

I architect **end-to-end data infrastructure** that powers AI systemsâ€”from raw data ingestion through web scraping and APIs, to semantic search infrastructure serving LLMs. My work bridges the gap between raw data chaos and production-ready AI applications.

### ğŸ”¥ Current Focus

- Building **production ETL pipelines** processing millions of records daily
- Implementing **modern data lakehouse** architectures (Bronze â†’ Silver â†’ Gold)
- Creating **RAG systems** combining lexical and semantic search
- Developing **data quality frameworks** with automated lineage tracking
- Maintaining **99.7% data pipeline reliability**

</div>

---

## ğŸ’¼ Professional Experience

### ğŸ¢ **Associate Data Science Engineer** @ [GetMySaas](https://getmysaas.com)
*Oct 2025 - Present | Remote*

<details open>
<summary><b>ğŸ“Š Key Responsibilities & Impact</b></summary>

<br/>

#### ğŸ”„ Data Pipeline Architecture
- Architecting **15+ production Airflow DAGs** orchestrating data from:
  - Social media APIs (X/Twitter API, Reddit API)
  - Web scraping workflows (Playwright, Scrapy crawlers)
  - Public datasets and third-party integrations
- **Impact:** Automated 100% of manual data collection, saving 40+ hours/week

#### ğŸ“„ Document Intelligence Pipeline
- Built end-to-end **document processing workflow**:
  - Apache Tika for text extraction
  - Tesseract OCR for scanned documents
  - Google Document AI for complex layouts
- **Impact:** Processing 10,000+ documents daily with 95% accuracy

#### ğŸ—ï¸ Modern Data Lakehouse
- Implemented **production-grade lakehouse architecture**:
  ```
  Airbyte Connectors â†’ S3/MinIO (Parquet Bronze) 
                    â†’ Apache Iceberg (Silver/Gold) 
                    â†’ dbt Transformations 
                    â†’ Trino Query Layer
  ```
- **Impact:** Reduced query time by 70%, enabled 50+ analysts

#### ğŸš€ Real-time Streaming Infrastructure
- Developed **event-driven pipelines** using:
  - Apache Kafka for message streaming
  - Redis for caching and URL frontier management
  - Real-time data enrichment and validation
- **Impact:** Sub-second data freshness for critical workflows

#### ğŸ” Hybrid Search System for RAG
- Built **semantic + lexical search infrastructure**:
  - OpenSearch for full-text search (BM25)
  - PostgreSQL + pgvector for semantic embeddings
  - Hybrid ranking algorithm combining both approaches
- **Impact:** Powers AI chatbot with 87% answer accuracy

#### âœ… Data Quality & Governance
- Established **data reliability framework**:
  - Great Expectations for automated validation
  - OpenLineage for end-to-end lineage tracking
  - OpenMetadata for data cataloging and discovery
- **Impact:** Reduced data incidents by 85%

#### ğŸ¤– AI-Assisted Development
- Daily use of Claude, GPT-5, and Perplexity for:
  - Code generation and debugging
  - Architecture design and optimization
  - Documentation and knowledge synthesis

</details>

---

### ğŸ“ **Graduate Research Assistant** @ IISER Tirupati
*Aug 2024 - Aug 2025*

- Built **transformer-based NLP models** achieving 87% F1-score on financial sentiment analysis
- Developed **ML applications** processing 50GB+ datasets with 99.7% data integrity
- Implemented **real-time ETL pipelines** reducing processing time by 60%
- Applied **A/B testing frameworks** improving model performance by 45%

---

## ğŸ› ï¸ Tech Stack

### ğŸ¯ Core Competencies

<table>
<tr>
  <td align="center" width="33%">
    <h4>ğŸ”„ Data Engineering</h4>
    <img src="https://skillicons.dev/icons?i=python,postgresql,kafka,redis,docker" />
    <br/>
    <img src="https://img.shields.io/badge/Apache_Airflow-017CEE?style=flat-square&logo=Apache%20Airflow&logoColor=white"/>
    <img src="https://img.shields.io/badge/dbt-FF694B?style=flat-square&logo=dbt&logoColor=white"/>
    <img src="https://img.shields.io/badge/Iceberg-1F8FD6?style=flat-square"/>
    <img src="https://img.shields.io/badge/Trino-DD00A1?style=flat-square"/>
  </td>
  <td align="center" width="33%">
    <h4>ğŸ¤– ML & AI</h4>
    <img src="https://skillicons.dev/icons?i=tensorflow,pytorch,sklearn" />
    <br/>
    <img src="https://img.shields.io/badge/Transformers-FFD21E?style=flat-square&logo=huggingface&logoColor=black"/>
    <img src="https://img.shields.io/badge/spaCy-09A3D5?style=flat-square"/>
    <img src="https://img.shields.io/badge/LangChain-121212?style=flat-square"/>
    <img src="https://img.shields.io/badge/MLflow-0194E2?style=flat-square"/>
  </td>
  <td align="center" width="33%">
    <h4>â˜ï¸ Cloud & DevOps</h4>
    <img src="https://skillicons.dev/icons?i=aws,git,linux,bash,github" />
    <br/>
    <img src="https://img.shields.io/badge/S3-569A31?style=flat-square&logo=amazons3&logoColor=white"/>
    <img src="https://img.shields.io/badge/EC2-FF9900?style=flat-square&logo=amazonec2&logoColor=white"/>
    <img src="https://img.shields.io/badge/Docker-2496ED?style=flat-square&logo=docker&logoColor=white"/>
  </td>
</tr>
</table>

### ğŸ“Š Proficiency Matrix

```mermaid
%%{init: {'theme':'dark'}}%%
graph LR
    A[Data Engineering] --> B[Expert: Airflow, dbt, Kafka]
    A --> C[Advanced: Iceberg, Trino, Airbyte]
    D[Machine Learning] --> E[Expert: scikit-learn, TensorFlow]
    D --> F[Advanced: Transformers, NLP, MLOps]
    G[Cloud & DevOps] --> H[Advanced: AWS, Docker, CI/CD]
    I[Databases] --> J[Expert: PostgreSQL, Redis]
    I --> K[Advanced: pgvector, OpenSearch]
```

### ğŸ”§ Full Technology Arsenal

<details>
<summary><b>Click to expand complete tech stack</b></summary>

**Data Orchestration & Workflow**
- Apache Airflow 3.x, Dagster, Prefect
- DAG design, task dependencies, dynamic workflows

**Streaming & Messaging**
- Apache Kafka, Redis Streams
- Event-driven architectures, pub-sub patterns

**Data Transformation**
- dbt (Data Build Tool), Pandas, PySpark
- SQL, Python data manipulation

**Storage & Lakehouse**
- Apache Iceberg, Delta Lake
- PostgreSQL, MySQL, MongoDB
- AWS S3, MinIO object storage

**Search & Retrieval**
- OpenSearch (Elasticsearch fork)
- PostgreSQL + pgvector for embeddings
- Hybrid search algorithms

**Data Quality & Observability**
- Great Expectations, OpenLineage
- OpenMetadata, Apache Atlas
- Data profiling and validation

**Web Scraping & APIs**
- Playwright, Scrapy, BeautifulSoup
- REST APIs, GraphQL
- API rate limiting and authentication

**Document Processing**
- Apache Tika, Tesseract OCR
- Google Document AI
- PDF parsing, image text extraction

**Machine Learning & AI**
- TensorFlow, PyTorch, scikit-learn
- Hugging Face Transformers
- LangChain, LlamaIndex
- Claude API, OpenAI API

**MLOps & Deployment**
- MLflow, DVC (Data Version Control)
- Docker, Kubernetes basics
- AWS SageMaker, EC2, Lambda

**Programming Languages**
- Python (Expert), SQL (Expert)
- Bash/Shell scripting
- YAML for configurations

**Version Control & CI/CD**
- Git, GitHub Actions
- Pre-commit hooks, code reviews

**Visualization & BI**
- Streamlit, Plotly
- Tableau basics, SQL dashboards

</details>

---

## ğŸš€ Featured Projects

<div align="center">

### ğŸ¯ Production Data Engineering Projects

</div>

---

### 1ï¸âƒ£ **Airbnb Data Pipeline: PostgreSQL â†’ S3** 
[![Repo](https://img.shields.io/badge/Repo-airflow--postgres--to--s3--pipeline-blue?style=for-the-badge&logo=github)](https://github.com/sumanthmalipeddi/airflow-postgres-to-s3-pipeline)
[![Stars](https://img.shields.io/github/stars/sumanthmalipeddi/airflow-postgres-to-s3-pipeline?style=for-the-badge)](https://github.com/sumanthmalipeddi/airflow-postgres-to-s3-pipeline/stargazers)

<div align="center">

#### ğŸ—ï¸ Architecture Overview

<img src="https://github.com/sumanthmalipeddi/airflow-postgres-to-s3-pipeline/blob/main/screenshots/full_architecture.png?raw=true" width="700" alt="Pipeline Architecture"/>

#### âœ… Successful DAG Execution

<img src="https://github.com/sumanthmalipeddi/airflow-postgres-to-s3-pipeline/blob/main/screenshots/Complete%20Success.png?raw=true" width="700" alt="Successful Execution"/>

</div>

#### ğŸ“ Project Overview

Production-grade **Apache Airflow 3.x pipeline** demonstrating real-world ETL best practices for Airbnb listing data.

#### ğŸ¯ Problem Statement

- Manual data exports from PostgreSQL to S3 taking hours
- Inconsistent CSV formatting causing downstream failures
- No idempotency - reruns creating duplicate records
- Lack of observability in data movement

#### ğŸ’¡ Solution Architecture

```yaml
Pipeline Flow:
  1. Data Ingestion:
     - Fetch Airbnb listings from PostgreSQL
     - Handle NULL semantics (\N vs empty strings)
     - Explicit column mapping for type safety

  2. Custom Operator:
     - Built PostgresToS3Operator using BaseOperator
     - Integrated PostgresHook & S3Hook
     - Airflow templating with {{ ds }} for traceability

  3. Data Export:
     - CSV serialization with proper encoding
     - S3 upload with partitioning by date
     - Idempotent design for safe reruns

  4. Error Handling:
     - Retry logic with exponential backoff
     - Data validation before export
     - Comprehensive logging
```

#### ğŸ”¥ Key Features

âœ… **Idempotent Batch Ingestion** - Safe DAG reruns without duplicates  
âœ… **Custom Airflow Operator** - Reusable across multiple projects  
âœ… **Production Error Handling** - Handles CSV NULL semantics, type mismatches  
âœ… **Airflow 3.x Compatible** - Uses latest Airflow features  
âœ… **Docker Compose Setup** - One-command local development

#### ğŸ› ï¸ Technical Deep Dive

<details>
<summary><b>Real-World Issues Solved</b></summary>

**Issue 1: CSV NULL Handling**
```python
# âŒ Wrong: Empty strings treated as NULL
COPY table FROM 'file.csv' WITH (FORMAT CSV)

# âœ… Correct: Explicit NULL representation
COPY table FROM 'file.csv' WITH (FORMAT CSV, NULL '\N')
```

**Issue 2: Type Mismatches**
```python
# Problem: "invalid input syntax for type numeric"
# Solution: Explicit column mapping with CAST
sql = '''
    COPY listings (id, price::numeric, name::text)
    FROM STDIN WITH CSV HEADER NULL '\N'
'''
```

**Issue 3: Duplicate Keys on Rerun**
```python
# Solution: Idempotent upsert pattern
sql = '''
    INSERT INTO listings VALUES (...)
    ON CONFLICT (id) DO UPDATE SET ...
'''
```

</details>

#### ğŸ“Š Performance Metrics

| Metric | Value |
|--------|-------|
| **Records Processed** | 50,000+ daily |
| **Pipeline Runtime** | ~45 seconds |
| **Success Rate** | 99.8% |
| **Data Freshness** | < 5 minutes |

#### ğŸ“ Key Learnings

- **CSV Hell**: NULL semantics, encoding issues, delimiter edge cases
- **Airflow Templating**: Using `{{ ds }}`, `{{ execution_date }}` for idempotency
- **Custom Operators**: Extending BaseOperator, using Hooks properly
- **Production Debugging**: Reading logs, understanding task retries

#### ğŸ’» Tech Stack

`Apache Airflow 3.x` `PostgreSQL` `AWS S3` `Python` `Docker` `Pandas`

---

### 2ï¸âƒ£ **Wikipedia Pageviews Analytics Pipeline**
[![Repo](https://img.shields.io/badge/Repo-wiki--pipeline-green?style=for-the-badge&logo=github)](https://github.com/sumanthmalipeddi/wiki-pipeline)
[![Stars](https://img.shields.io/github/stars/sumanthmalipeddi/wiki-pipeline?style=for-the-badge)](https://github.com/sumanthmalipeddi/wiki-pipeline/stargazers)

<div align="center">

#### ğŸ“Š DAG Success Graph

<img src="https://github.com/sumanthmalipeddi/wiki-pipeline/blob/main/images/graph_success.png?raw=true" width="700" alt="DAG Graph"/>

#### âœ… Workflow Execution

<img src="https://github.com/sumanthmalipeddi/wiki-pipeline/blob/main/images/workflow_success.png?raw=true" width="700" alt="Workflow Success"/>

</div>

#### ğŸ“ Project Overview

Automated **hourly ETL pipeline** tracking Wikipedia pageview statistics for tech companies using distributed task execution.

#### ğŸ¯ Problem Statement

- Manual Wikipedia dump downloads inefficient
- Need real-time pageview tracking for trend analysis
- Processing large compressed files (500MB+ hourly)
- Ensuring pipeline reliability for 24/7 operation

#### ğŸ’¡ Solution Architecture

```yaml
Architecture Components:

  Orchestration Layer:
    - Apache Airflow 3.1.5
    - CeleryExecutor for distributed processing
    - Redis as message broker

  Data Flow:
    1. Download Phase (27s):
       - Fetch Wikipedia pageview dumps (hourly)
       - Decompress gzip files
       - Validate file integrity

    2. Transform Phase (2s):
       - Filter tech company pages
       - Aggregate view counts
       - Handle encoding issues

    3. Load Phase (<1s):
       - Bulk insert to PostgreSQL 16
       - Create time-series indexes
       - Update aggregate tables

  Infrastructure:
    - Docker Compose orchestration
    - PostgreSQL for analytics
    - Redis for task queue
    - Celery workers (3 instances)
```

#### ğŸ”¥ Key Features

âœ… **Sub-40 Second Full ETL** - Optimized for performance  
âœ… **Distributed Processing** - CeleryExecutor scales horizontally  
âœ… **Fault Tolerant** - Automatic retries and error recovery  
âœ… **Real-time Monitoring** - Airflow UI dashboards  
âœ… **Production Ready** - Docker containerization

#### ğŸ“Š Performance Breakdown

| Phase | Duration | Optimization |
|-------|----------|--------------|
| **Download & Extract** | 27s | Parallel downloads, streaming decompression |
| **Transform** | 2s | In-memory processing, efficient filtering |
| **Load** | <1s | Bulk inserts, connection pooling |
| **Total Pipeline** | ~39s | End-to-end automation |

#### ğŸ› ï¸ Technical Implementation

<details>
<summary><b>CeleryExecutor Configuration</b></summary>

```python
# airflow.cfg
executor = CeleryExecutor

[celery]
broker_url = redis://redis:6379/0
result_backend = db+postgresql://airflow:airflow@postgres/airflow
worker_concurrency = 4
```

**Benefits:**
- Horizontal scaling: Add workers as needed
- Task isolation: Failed tasks don't affect others
- Better resource utilization

</details>

<details>
<summary><b>Data Transformation Logic</b></summary>

```python
# Filter top tech companies
companies = ['Google', 'Amazon', 'Apple', 'Microsoft', 'Facebook']

# Efficient filtering using generators
def process_pageviews(dump_file):
    for line in decompress_stream(dump_file):
        page, views = parse_line(line)
        if any(company in page for company in companies):
            yield {
                'page': page,
                'views': int(views),
                'timestamp': datetime.utcnow()
            }
```

</details>

#### ğŸ“ Key Learnings

- **Distributed Systems**: CeleryExecutor vs LocalExecutor tradeoffs
- **Performance Tuning**: Streaming vs batch processing
- **Docker Networking**: Service discovery, health checks
- **Monitoring**: Airflow metrics, log aggregation

#### ğŸ’» Tech Stack

`Apache Airflow 3.1.5` `PostgreSQL 16` `Celery` `Redis` `Docker Compose` `Python`

---

### 3ï¸âƒ£ **Prompt Engineering Study Repository**
[![Repo](https://img.shields.io/badge/Repo-promptengineering__study-purple?style=for-the-badge&logo=github)](https://github.com/sumanthmalipeddi/promptengineering_study)
[![Stars](https://img.shields.io/github/stars/sumanthmalipeddi/promptengineering_study?style=for-the-badge)](https://github.com/sumanthmalipeddi/promptengineering_study/stargazers)

#### ğŸ“ Project Overview

Systematic exploration of **prompt engineering techniques** for production LLM applications and RAG systems.

#### ğŸ¯ Research Focus

Building reliable, reproducible prompting patterns for:
- Classification tasks (sentiment, intent, entity types)
- Summarization (financial reports, technical docs)
- Reasoning (multi-step problem solving, CoT)
- RAG systems (query rewriting, context ranking)

#### ğŸ’¡ Study Areas

```yaml
Prompt Patterns Explored:

1. Few-Shot Learning:
   - 0-shot vs 1-shot vs 5-shot comparison
   - Example selection strategies
   - Task-specific template design

2. Chain-of-Thought (CoT):
   - Step-by-step reasoning prompts
   - Self-consistency sampling
   - CoT vs direct prompting benchmarks

3. Role-Based Prompting:
   - System message engineering
   - Persona consistency
   - Domain expert emulation

4. Structured Output:
   - JSON mode forcing
   - Schema-guided generation
   - Pydantic model integration

5. RAG-Specific Techniques:
   - Query decomposition
   - Hypothetical document embeddings
   - Re-ranking prompts
```

#### ğŸ”¬ Experimental Setup

<details>
<summary><b>Evaluation Framework</b></summary>

```python
# Systematic prompt testing
experiments = [
    {
        'technique': 'few_shot',
        'variants': [0, 1, 3, 5],  # number of examples
        'metrics': ['accuracy', 'consistency', 'latency']
    },
    {
        'technique': 'cot',
        'variants': ['standard', 'self_consistency', 'least_to_most'],
        'metrics': ['reasoning_quality', 'answer_accuracy']
    }
]

# Models tested: GPT-4, Claude 3.5, Llama 3
```

</details>

#### ğŸ“Š Key Findings

| Technique | Use Case | Improvement |
|-----------|----------|-------------|
| **Few-Shot** | Classification | +23% accuracy vs 0-shot |
| **CoT** | Math reasoning | +41% correct answers |
| **Role-Based** | Domain tasks | +18% expert alignment |
| **Structured Output** | Data extraction | -67% parsing errors |

#### ğŸ“ Practical Applications

- **Resume Analyzer**: 5-shot prompting for skill extraction
- **Financial Sentiment**: CoT for nuanced sentiment reasoning
- **RAG Query Rewriter**: Decomposition for better retrieval

#### ğŸ’» Tech Stack

`Python` `LangChain` `OpenAI API` `Claude API` `Jupyter` `Pandas`

---

### 4ï¸âƒ£ **Spotify Trending Telugu Songs ETL**
[![Repo](https://img.shields.io/badge/Repo-spotify__trending__telugu-1DB954?style=for-the-badge&logo=spotify)](https://github.com/sumanthmalipeddi/spotify_trending_telugu)

<div align="center">

#### ğŸµ ETL Architecture

<img src="https://github.com/sumanthmalipeddi/spotify_trending_telugu/blob/main/Architecture.png?raw=true" width="700" alt="Spotify ETL Architecture"/>

</div>

#### ğŸ“ Project Overview

Serverless ETL pipeline extracting trending Telugu music data from Spotify API to AWS S3.

#### ğŸ’¡ Architecture Highlights

- **AWS Lambda** for serverless execution
- **CloudWatch Events** for scheduled triggers
- **Spotipy SDK** for API interactions
- **S3** for data lake storage

#### ğŸ”¥ Features

âœ… Automated daily music trend collection  
âœ… Serverless architecture (no infrastructure management)  
âœ… Cost-efficient (pay-per-execution)  
âœ… JSON to Parquet transformation

#### ğŸ’» Tech Stack

`AWS Lambda` `Spotipy API` `AWS S3` `CloudWatch` `Python`

---

### 5ï¸âƒ£ **Skills & Resume Intelligence Analyzer**
[![Repo](https://img.shields.io/badge/Repo-llm__carrerasst-orange?style=for-the-badge&logo=github)](https://github.com/sumanthmalipeddi/llm_carrerasst)

#### ğŸ“ Project Overview

AI-powered web application for **resume analysis**, **ATS scoring**, and **salary prediction** using NLP.

#### ğŸ’¡ Key Features

âœ… **Named Entity Recognition** - Extract skills, education, experience  
âœ… **ATS Alignment Scoring** - Match resume to job descriptions  
âœ… **Salary Prediction** - XGBoost model with 50GB+ training data  
âœ… **Streamlit UI** - Interactive, user-friendly interface

#### ğŸ“Š Model Performance

| Metric | Value |
|--------|-------|
| **Skill Extraction Accuracy** | 94.2% |
| **Salary Prediction MAE** | $3,200 |
| **Processing Time** | < 2 seconds |

#### ğŸ’» Tech Stack

`Streamlit` `spaCy` `XGBoost` `Scikit-learn` `AWS EC2` `NLP`

---

### 6ï¸âƒ£ **Housing Data Analytics & Engineering**
[![Repo](https://img.shields.io/badge/Repo-Housing__Data--Analytics--Engineering-red?style=for-the-badge&logo=github)](https://github.com/sumanthmalipeddi/Housing_Data-Analytics-Engineering)

#### ğŸ“ Project Overview

Comprehensive demonstration of **modern data engineering** techniques applied to real estate market data.

#### ğŸ’¡ ETL Pipeline

- Data extraction from multiple sources
- Transformation using Pandas and SQL
- Visualization with Plotly
- Statistical analysis and modeling

#### ğŸ’» Tech Stack

`Python` `Jupyter` `Pandas` `SQL` `Plotly` `NumPy`

---

## ğŸ“Š GitHub Analytics

<div align="center">

### ğŸ“ˆ Contribution Stats

<img height="180em" src="https://github-readme-stats.vercel.app/api?username=sumanthmalipeddi&show_icons=true&theme=tokyonight&include_all_commits=true&count_private=true&hide_border=true&bg_color=0D1117&title_color=3B9CFF&icon_color=3B9CFF&text_color=C9D1D9&rank_icon=github"/>
<img height="180em" src="https://github-readme-stats.vercel.app/api/top-langs/?username=sumanthmalipeddi&layout=compact&theme=tokyonight&hide_border=true&bg_color=0D1117&title_color=3B9CFF&text_color=C9D1D9&langs_count=8"/>

### ğŸ”¥ Contribution Streak

[![GitHub Streak](https://github-readme-streak-stats.herokuapp.com?user=sumanthmalipeddi&theme=tokyonight&hide_border=true&background=0D1117&ring=3B9CFF&fire=3B9CFF&currStreakLabel=3B9CFF&sideNums=3B9CFF&currStreakNum=FFFFFF&sideLabels=C9D1D9&dates=C9D1D9)](https://git.io/streak-stats)

### ğŸ“Š Activity Graph

![Activity Graph](https://github-readme-activity-graph.vercel.app/graph?username=sumanthmalipeddi&theme=tokyo-night&hide_border=true&bg_color=0D1117&color=3B9CFF&line=3B9CFF&point=FFFFFF&area=true&area_color=3B9CFF)

### ğŸ† GitHub Trophies

<img src="https://github-profile-trophy.vercel.app/?username=sumanthmalipeddi&theme=tokyonight&no-frame=true&no-bg=true&margin-w=4&column=7" width="100%"/>

</div>

---

## ğŸ† Achievements & Certifications

<div align="center">

<table>
<tr>
  <th>ğŸ“ Certification</th>
  <th>ğŸ¢ Issuer</th>
  <th>ğŸ“… Date</th>
  <th>ğŸ”— Credential</th>
</tr>
<tr>
  <td><b>MS Data Science & AI</b><br/>CGPA: 9.50/10</td>
  <td>IISER Tirupati</td>
  <td>Aug 2025</td>
  <td>-</td>
</tr>
<tr>
  <td><b>Complete Data Science, ML, DL, NLP Bootcamp</b></td>
  <td>Udemy</td>
  <td>Apr 2025</td>
  <td><a href="https://udemy-certificate.s3.amazonaws.com/image/UC-04059c6b-c210-4409-bb19-1c1bdb005c16.jpg">View</a></td>
</tr>
<tr>
  <td><b>Mathematics for Data Science & GenAI</b></td>
  <td>Udemy</td>
  <td>Oct 2024</td>
  <td><a href="https://www.udemy.com/certificate/UC-385046d4-6cfd-475a-a4f3-557f1bd091f3/">View</a></td>
</tr>
<tr>
  <td><b>AWS Cloud Practitioner Essentials</b></td>
  <td>AWS</td>
  <td>2024</td>
  <td>-</td>
</tr>
</table>

</div>

---

## ğŸ“š Learning Journey

### ğŸ”¥ Current Learning Streak: 120+ Days

<div align="center">

```mermaid
gantt
    title 2026 Learning Roadmap
    dateFormat  YYYY-MM-DD
    section Data Engineering
    Airflow Deep Dive           :done, 2025-12-01, 60d
    Kafka Streaming             :active, 2026-01-15, 45d
    dbt Advanced Patterns       :active, 2026-02-01, 30d
    Apache Iceberg              :2026-02-15, 45d
    section DSA
    Daily LeetCode              :done, 2025-10-01, 120d
    System Design               :active, 2026-01-01, 90d
    section Cloud
    Snowflake Training          :active, 2026-01-20, 40d
    AWS Solutions Architect     :2026-03-01, 60d
```

</div>

### ğŸ“– Currently Reading

| ğŸ“š Book | ğŸ‘¤ Author | ğŸ“Š Progress |
|---------|-----------|-------------|
| **Fundamentals of Data Engineering** | Joe Reis & Matt Housley | â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‘â–‘ 80% |
| **Designing Data-Intensive Applications** | Martin Kleppmann | â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‘â–‘â–‘â–‘ 60% |
| **System Design Interview Vol. 2** | Alex Xu | â–ˆâ–ˆâ–ˆâ–ˆâ–‘â–‘â–‘â–‘â–‘â–‘ 40% |

### ğŸ“ Recent Activity Log

<details open>
<summary><b>ğŸ—“ï¸ February 2026 Progress</b></summary>

```python
learning_log = {
    "Day 136": {
        "topic": "Apache Airflow - Custom Operators",
        "achievement": "Built PostgresToS3Operator with templating",
        "learning": "Understanding BaseOperator, Hooks, and XComs"
    },
    "Day 135": {
        "topic": "ETL Pipeline Design",
        "achievement": "Postgres â†’ S3 â†’ Docker Pandas workflow",
        "learning": "Idempotency patterns, DAG dependencies"
    },
    "Day 134": {
        "topic": "DSA - Dynamic Programming",
        "achievement": "Kadane's Algorithm O(n) solution",
        "learning": "Subarray optimization, DP state management"
    },
    "Day 131": {
        "topic": "Algorithms - Dutch National Flag",
        "achievement": "3-way partitioning in O(n)",
        "learning": "In-place sorting, pointer manipulation"
    },
    "Day 130": {
        "topic": "Airflow - Branching & Trigger Rules",
        "achievement": "BranchPythonOperator implementation",
        "learning": "Conditional workflows, none_failed trigger"
    }
}
```

</details>

### ğŸ“Š Skills Development Progress

<div align="center">

| Skill | Proficiency | Hours Invested |
|-------|-------------|----------------|
| Apache Airflow | â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‘â–‘ 85% | 300+ hours |
| Apache Kafka | â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‘â–‘â–‘ 70% | 150+ hours |
| PostgreSQL | â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‘ 90% | 400+ hours |
| Python | â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‘ 95% | 1000+ hours |
| dbt | â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‘â–‘â–‘â–‘ 65% | 100+ hours |
| DSA | â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‘â–‘â–‘ 75% | 250+ hours |

</div>

---

## ğŸ“ Education

### ğŸ“ **Indian Institute of Science Education and Research (IISER) Tirupati**

<table>
<tr>
<td width="70%">

**Master of Science - Data Science & Artificial Intelligence**  
*Aug 2024 - Aug 2025*

**CGPA: 9.50/10** ğŸ†

#### ğŸ“š Relevant Coursework
- Mathematics & Statistics for Data Science
- Data Structures & Algorithms
- Database Management Systems
- Machine Learning & Deep Learning
- Statistical Analysis & Hypothesis Testing
- Natural Language Processing
- Big Data Analytics & ETL Pipelines
- Cloud Computing & MLOps

</td>
<td width="30%" align="center">

<img src="https://img.shields.io/badge/CGPA-9.50%2F10-brightgreen?style=for-the-badge" alt="CGPA"/>

<img src="https://img.shields.io/badge/Rank-Top%205%25-blue?style=for-the-badge" alt="Rank"/>

</td>
</tr>
</table>

#### ğŸ”¬ Key Academic Projects

<details>
<summary><b>1. Financial Sentiment Analysis with Transformers</b></summary>

- Fine-tuned BERT model on financial news corpus (10M+ tokens)
- Achieved **87% F1-score** on multi-class sentiment classification
- Deployed model API serving 1000+ requests/day
- **Tech:** Transformers, PyTorch, FastAPI, Docker

</details>

<details>
<summary><b>2. Real-time ETL Pipeline for IoT Sensors</b></summary>

- Built streaming pipeline processing 10K events/second
- **60% reduction** in data processing latency
- Implemented anomaly detection with 95% accuracy
- **Tech:** Kafka, Flink, TimescaleDB, Grafana

</details>

<details>
<summary><b>3. A/B Testing Framework for ML Models</b></summary>

- Designed experimentation platform for model deployment
- **45% improvement** in model performance metrics
- Automated statistical significance testing
- **Tech:** Python, PostgreSQL, Streamlit, MLflow

</details>

---

### ğŸ“ **SASTRA University**

**Bachelor of Technology - Civil Engineering**  
*2014 - 2018 | CGPA: 8.542*

- Top performer in mathematics and analytics
- Foundation in problem-solving and data-driven decision making
- Transitioned to Data Science through self-learning and upskilling

---

## ğŸ“« Let's Connect

<div align="center">

<img src="https://capsule-render.vercel.app/api?type=waving&color=gradient&customColorList=6,11,20&height=100&section=header&text=Get%20In%20Touch&fontSize=30&fontColor=fff&animation=twinkling" width="100%"/>

<h3>I'm always open to interesting conversations and collaboration opportunities!</h3>

<table>
<tr>
<td align="center" width="33%">

### ğŸ’¼ Professional

<a href="https://linkedin.com/in/sumanth-malipeddi">
<img src="https://img.shields.io/badge/LinkedIn-0077B5?style=for-the-badge&logo=linkedin&logoColor=white" alt="LinkedIn"/>
</a>

**Connect for:**
- Job opportunities
- Professional networking
- Project collaborations

</td>
<td align="center" width="33%">

### ğŸ’» Technical

<a href="https://github.com/sumanthmalipeddi">
<img src="https://img.shields.io/badge/GitHub-181717?style=for-the-badge&logo=github&logoColor=white" alt="GitHub"/>
</a>

**Explore:**
- Open source projects
- Code contributions
- Technical discussions

</td>
<td align="center" width="33%">

### ğŸ“§ Direct Contact

<a href="mailto:sumanth.9666@gmail.com">
<img src="https://img.shields.io/badge/Email-D14836?style=for-the-badge&logo=gmail&logoColor=white" alt="Email"/>
</a>

**Reach out for:**
- Mentorship requests
- Speaking opportunities
- Technical consultations

</td>
</tr>
</table>

<a href="https://x.com/Sumanth9666">
<img src="https://img.shields.io/badge/Twitter-1DA1F2?style=for-the-badge&logo=x&logoColor=white" alt="Twitter"/>
</a>

---

### ğŸ¯ Open To Opportunities

<table>
<tr>
<td align="center" width="33%">

**ğŸ”§ Data Engineering**

Building scalable ETL pipelines  
Lakehouse architectures  
Real-time streaming systems

</td>
<td align="center" width="33%">

**ğŸ¤– ML Engineering**

Model deployment & serving  
MLOps pipelines  
Feature engineering

</td>
<td align="center" width="33%">

**ğŸ§  AI Engineering**

RAG systems  
Semantic search  
LLM integration

</td>
</tr>
</table>

---

### ğŸ“Š Quick Stats

<img src="https://img.shields.io/badge/Experience-4%2B%20Years-blue?style=for-the-badge"/>
<img src="https://img.shields.io/badge/Projects-31%2B-green?style=for-the-badge"/>
<img src="https://img.shields.io/badge/DSA%20Streak-120%2B%20Days-orange?style=for-the-badge"/>
<img src="https://img.shields.io/badge/LinkedIn-2.3K%20Followers-blue?style=for-the-badge"/>

---

### ğŸ’¡ Fun Facts

```python
fun_facts = {
    "ğŸ¯ Philosophy": "Production pipelines live in edge cases",
    "â˜• Code Fuel": "Coffee + Claude AI",
    "ğŸµ Coding Music": "Lo-fi beats + focus playlists",
    "ğŸ“š Learning Style": "Build â†’ Break â†’ Learn â†’ Document",
    "ğŸŒŸ Motivation": "Every failed DAG run is a lesson",
    "ğŸš€ Goal": "Building data systems that power the future"
}
```

</div>

---

<div align="center">

<img src="https://capsule-render.vercel.app/api?type=waving&color=gradient&customColorList=6,11,20&height=120&section=footer" width="100%"/>

<h3>â­ If you find my work helpful, consider starring my repositories!</h3>

<p>
<img src="https://img.shields.io/badge/Made%20with-â¤ï¸%20and%20â˜•-red?style=for-the-badge"/>
<img src="https://img.shields.io/badge/Powered%20by-Curiosity%20%26%20Code-blue?style=for-the-badge"/>
</p>

<h4>Â© 2026 Sumanth Malipeddi | Building production systems one pipeline at a time ğŸš€</h4>

**"The best way to predict the future is to build it."**

<sub>Last updated: February 2026</sub>

</div>
